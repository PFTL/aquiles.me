# How to make more published research true

Literature note on [@ioannidis2014]

This is the **status quo** on which the essay builds upon:

- Research is an industry with over 15M people authoring papers (25M were published between 1996 and 2011)
- Results and applications are exaggerated, translation (i.e. [[technology transfer]]) is slow and inefficient
- 85% of research resources are wasted (#TODO: check reference # 5)
- Non-meritocratic practices like nepotism, sexism, unwarranted conservatism are probably widespread
- There is little experimental evidence on how peer review should be done and when (protocol-based, manuscript-based, post-publication)
- Scientific structures can be traced back to the Middle Ages (academic hierarchies) or the 17th century: professional societies, journal publishing. Is this still valid today?

And it proposes some **effective interventions**:

- Diminish biases, conflicts of interests, fragmentation and work towards transparency, collaborative research. 
- Interventions to change the status quo can lead to more resources wasted, or generate collateral damage
-     What does this mean?
    > A system that focuses too much on eliminating discrimination, also eliminates the reasonable discrimination required to make wise choices.
- Build incentives for large-scale collaborative research with a strong replication culture (genetic epidemiology seems to have gone through these changes). This is somehow contradictory to the changes discussed in [[20210223190134]]
- **Replication** should be feasible by default, meaning that it has to be taken into account for the experimental design, and has to be taken into account by the research agendas of the different funding bodies. 
- **Registration** of trials and results increases transparency, but it can also trigger unwanted consequences; e.g.: bad data analysis to claim spurious effects of a drug is, perhaps, harder to combat than "good" science. But nonetheless the end goal is to increase trust and credibility of the research done. 
- **Statistical methods** must be defined upfront, and there must be training and continuous education of researchers to perform proper analysis. 
- #TODO: check the EQUATOR initiative on how to [[change peer review]]

But we should also take into account the **stakeholders** involved in the entire publishing circle:

- Stakeholders cherish research from different perspectives. Funding bodies may want published papers, or translatable into applications, or profitable. Different stakeholders may have contradicting views on what research should be. 
- What happens if the *same* stakeholder wears many hats? An academic researcher may be the CSO of a spin-out company, may be the editor of a journal, reviewer of grants, etc. How do the conflicts affect the best interests when wearing the other hats? 

[[Papers are research currencies]], that can purchase promotion and other power. However, they are not the only currency. Being allocated a grant can also be used to get a promotion. Therefore, one must ask what is the exchange rate between these currencies? Is supervising 5 postdocs equivalent to publishing 15 papers? Not all fields are the same, people working in interface disciplines will have a hard time. Moreover, the exchange rate is not known, and therefore planning careers and prioritizing is almost impossible. 

A possibility is to change the **reward system** (some other ideas are discussed in [[20210223190134]]). One could think of ways in which open science, reproducibility, sharing, community building, etc. become currencies researchers can exchange, in the same way a published paper or a grant does. If institutions force higher exchange rates for these currencies, more researchers will naturally pursue them. 

> Interventions to make science less wasteful and more effective could be hugely beneficial to our health, our comfort, and our grasp of truth and could help scientific research more successfully pursue its noble goals. 

Tags: #research-management #science #research-incentives #paper-publishing